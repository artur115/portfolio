{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e878fb2-8f79-423c-b98c-b47bb5713cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Python version needs to be >3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b916ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182145af-eb90-474d-9e2b-364ad3de4bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary packages with correct Jupyter syntax\n",
    "!pip install gradio==4.44.0 \\\n",
    "gradio==4.44.0 \\\n",
    "ibm-watsonx-ai==1.1.2  \\\n",
    "langchain==0.2.11 \\\n",
    "langchain-community==0.2.10 \\\n",
    "langchain-ibm==0.1.11 \\\n",
    "chromadb==0.4.24 \\\n",
    "pypdf==4.3.1 \\\n",
    "pydantic==2.9.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ad1e29-0686-4547-81bc-79f68cd872c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import the necessary libraries\n",
    "## Run Gradio Interface to read your files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab51e9bd-681f-411d-a17a-d0bcb9374aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from langchain_ibm import WatsonxLLM, WatsonxEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "## LLM\n",
    "def get_llm():\n",
    "    model_id = 'mistralai/mixtral-8x7b-instruct-v01'\n",
    "    parameters = {\n",
    "        GenParams.MAX_NEW_TOKENS: 256,\n",
    "        GenParams.TEMPERATURE: 0.5,\n",
    "    }\n",
    "    project_id = \"skills-network\"\n",
    "    watsonx_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "        project_id=project_id,\n",
    "        params=parameters,\n",
    "    )\n",
    "    return watsonx_llm\n",
    "\n",
    "## Document loader\n",
    "def document_loader(file):\n",
    "    loader = PyPDFLoader(file.name)\n",
    "    loaded_document = loader.load()\n",
    "    return loaded_document\n",
    "\n",
    "## Text splitter\n",
    "def text_splitter(data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "\n",
    "## Vector db\n",
    "def vector_database(chunks):\n",
    "    embedding_model = watsonx_embedding()\n",
    "    vectordb = Chroma.from_documents(chunks, embedding_model)\n",
    "    return vectordb\n",
    "\n",
    "## Embedding model\n",
    "def watsonx_embedding():\n",
    "    embed_params = {\n",
    "        EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,\n",
    "        EmbedTextParamsMetaNames.RETURN_OPTIONS: {\"input_text\": True},\n",
    "    }\n",
    "    watsonx_embedding = WatsonxEmbeddings(\n",
    "        model_id=\"ibm/slate-125m-english-rtrvr\",\n",
    "        url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "        project_id=\"skills-network\",\n",
    "        params=embed_params,\n",
    "    )\n",
    "    return watsonx_embedding\n",
    "\n",
    "## Retriever\n",
    "def retriever(file):\n",
    "    splits = document_loader(file)\n",
    "    chunks = text_splitter(splits)\n",
    "    vectordb = vector_database(chunks)\n",
    "    retriever = vectordb.as_retriever()\n",
    "    return retriever\n",
    "\n",
    "## QA Chain\n",
    "def retriever_qa(file, query):\n",
    "    llm = get_llm()\n",
    "    retriever_obj = retriever(file)\n",
    "    qa = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                    chain_type=\"stuff\", \n",
    "                                    retriever=retriever_obj, \n",
    "                                    return_source_documents=False)\n",
    "    response = qa.invoke(query)\n",
    "    return response['result']\n",
    "\n",
    "\n",
    "# Create Gradio interface\n",
    "rag_application = gr.Interface(\n",
    "    fn=retriever_qa,\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload PDF File\", file_count=\"single\", file_types=['.pdf'], type=\"filepath\"),  # Drag and drop file upload\n",
    "        gr.Textbox(label=\"Input Query\", lines=2, placeholder=\"Type your question here...\")\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Output\"),\n",
    "    title=\"RAG Chatbot\",\n",
    "    description=\"Upload a PDF document and ask any question. The chatbot will try to answer using the provided document.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "rag_application.launch(server_name=\"0.0.0.0\", share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
